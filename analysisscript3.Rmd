---
title: Module- Machine Learning Models I"
author: "Priyanka"
date: "11/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#load needed packages.
```{r}
library(readxl) #for loading Excel files
library(dplyr) #for data processing
library(here) #to set paths
library(tidyr)
library(rpart.plot) #for visualizing a decision tree
library(vip) #for variable importance plots
library(ranger)
library(glmnet)
library(tidymodels)
library(tidyverse)
```
## Load Data

```{r}
data_location <- here::here("files","processeddata.rds")

cleaneddata <- readRDS(data_location)

cleaneddata
``` 
 
## Pre-processing-Variable removal

## Removing WeaknessYN, CoughYN ,  CoughYN2 and MyalgiaYN exist on both a severity score and as Yes/No

```{r}

data_var_Rem <- dplyr::select(cleaneddata, -c(WeaknessYN, MyalgiaYN, CoughYN, CoughYN2))

```

##Coding three ordered factors (Weakness, CoughIntensity, Myalgia)

```{r}
data_var_Rem <- mutate(data_var_Rem, Weakness = factor(Weakness, levels = c("None", "Mild","Moderate","Severe"),ordered = TRUE))

data_var_Rem <- mutate(data_var_Rem, CoughIntensity= factor(CoughIntensity, levels = c("None", "Mild","Moderate","Severe"),ordered = TRUE))

data_var_Rem <- mutate(data_var_Rem, Myalgia = factor(Myalgia , levels = c("None", "Mild","Moderate","Severe"),ordered = TRUE))

data_var_Rem

```


#Removing unbalanced binary predictors

```{r}

data_bi_pre_rem <- subset(data_var_Rem, select = -c(Hearing, Vision))

data_bi_pre_rem

```



#setting random seed to 123

```{r}
set.seed(123)
```

#Split the data 
```{r}
##70% of the data into the training set and 30% into testing

data_split <- initial_split(data_bi_pre_rem, prop = 3/4, strata = BodyTemp)
```

# Create data frames for the two sets:
```{r}

train_data <- training(data_split)
test_data  <- testing(data_split)
```

# 5-fold cross-validation
```{r}

fold_5_data<- vfold_cv(train_data, v = 5, repeats = 5, strata = BodyTemp)
```



# Creating a recipe 

```{r}
recipe_BT <- recipe(BodyTemp ~ ., data = train_data) %>% step_dummy(all_predictors())
```

     
#Null model performance
```{r}

# Creates a recipe that fits null model

BT_rec_null <- recipe(BodyTemp ~  1 , data = train_data)
```

#Build a model specification

```{r}
lm_mod <- linear_reg() %>%
    set_engine("lm")

```
# Null Model Workflow
```{r}
null_wflow <-
  workflow() %>% 
  add_model(lm_mod) %>% 
  add_recipe(BT_rec_null)
```

```{r}
null_fit<-
  null_wflow %>%
  fit(data = train_data )
```

# Predictions based on null model
```{r}
prediction_train<-predict(null_fit, train_data)

prediction_test <-predict(null_fit, test_data)

prediction_train

prediction_test
```


##The steps (block of code) you should have here are :
##1) model specification,
##2) workflow definition, 
##3) tuning grid specification and 
##4) tuning using cross-validation and the tune_grid() function


##1) model specification

```{r}

tune_spec <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()
  ) %>% 
  set_engine("rpart") %>% 
  set_mode("regression")
```

#Tune grid specification:
```{r}
tree_grid <-
  grid_regular(cost_complexity(),
               tree_depth(),
               levels = 5)

##25 different possible tuning combinations

tree_grid
```

#Workflow definition
```{r}
tree_workflow <- workflow() %>%
    add_model(tune_spec) %>%
     add_recipe(recipe_BT)


tree_res <- tree_workflow %>%
     tune::tune_grid(resamples = folds,
                     grid = tree_grid,
                     control = control_grid(verbose = FALSE, save_pred = TRUE),                                    metrics = metric_set(rmse))
```


##The function collect_metrics() gives us a tidy tibble with all the results

```{r}
  tree_res %>% 
   collect_metrics()


tree_res %>% autoplot()
   

### Show best
tree_res %>%
     show_best("rmse")
     
```

#Pull out the single set of hyperparameter values for our best decision tree model

```{r}
best_tree <- tree_res %>%
     select_best("rmse")

best_tree
```

##Finalize Model

```{r}
final_wf <- 
    tree_workflow %>% 
    finalize_workflow(best_tree)

 final_wf
```
##fit this final model to the training data and use our test data to estimate the model performance

```{r}
final_fit <- 
     final_wf %>%
    last_fit(data_split)

final_fit %>%
  collect_metrics()
```

## rmse    standard      1.13 


## LASSO Model

# model specification

```{r}
lasso_mod <- 
  linear_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")
```

# Create a workflow


#Workflow
```{r}
lasso_workflow <-
  workflow() %>%
  add_model(lasso_mod) %>%
  add_recipe(recipe_BT)
```

```{r}
lasso_mod <- 
  linear_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")
```

##Tuning

```{r}
lasso_grid <- tibble(penalty = 10^seq(-4,-1,length.out = 30))


lasso_res <-
    lasso_workflow %>%
     tune_grid(fold_5_data,
grid = lasso_grid,
               control = 
                   control_grid(save_pred = TRUE),
              metrics = 
                   metric_set(rmse))



 lasso_res
 
 
 
 best_model <- lasso_res %>%
    show_best("rmse", n = 15) %>%
    arrange(penalty)
 
 
best_model 
```


## random forest model
```{r}

cores <- parallel::detectCores()
cores

  
rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
  set_engine("ranger", num.threads = cores) %>% 
  set_mode("regression")



 rf_workflow <-
    workflow() %>%
    add_model(rf_mod) %>%
    add_recipe(recipe_BT)

# 3/4) create tuning grid/tune hyperparameters 
rf_grid  <- expand.grid(mtry = c(3, 4, 5, 6), min_n = c(40,50,60), trees = c(500,1000)  )
 

rf_resample <- 
    rf_workflow %>% 
    tune_grid(fold_5_data,
               grid = 25,
               control = control_grid(save_pred = TRUE),
               metrics = metric_set(rmse))

#Looking at the models created by random forest
rf_resample %>%
   collect_metrics()



#  autoplot the results 
rf_resample %>% autoplot()

# select best  combination 
rf_resample %>%
   show_best()


#Selects best performing model
best_rf <- rf_resample %>%
  select_best()

# finalize workflow 
rf_final_wf <- 
     rf_workflow %>% 
     finalize_workflow(best_rf)

fit_best_forest <- rf_final_wf %>% 
  fit(data = train_data)


# Use a trained workflow to predict section using train data

predict(fit_best_forest, new_data = train_data)


# include predicted probabilities

aug_best_forest <- augment(fit_best_forest, new_data = train_data)


# estimate model performance with rmse 
forest_rmse <- aug_best_forest %>% 
  rmse(truth = BodyTemp, .pred) %>% 
  mutate(model = 'Random Forest')


#  Make diagnostic plots 

#plot actual vs fitted 

ggplot(data = aug_best_forest, aes(x = .pred, y = BodyTemp)) +
  geom_point()

#plot residuals vs fitted 

aug_best_forest %>% 
  mutate(resid = BodyTemp - .pred) %>% 
  ggplot(aes(x = .pred, y = resid)) +
  geom_point()
```
